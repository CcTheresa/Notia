import json
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import os

print("ğŸ”§ Creating embeddings for layered advice...\n")

# Load flattened layered advice
print("ğŸ“‚ Loading flattened data...")
with open('processed_data/flattened_layered_advice.json', 'r', encoding='utf-8') as f:
    documents = json.load(f)

print(f"âœ… Loaded {len(documents)} layer records\n")

# Load model
print("ğŸ§  Loading sentence transformer...")
model = SentenceTransformer('all-MiniLM-L6-v2')
print("âœ… Model loaded (384-dim)\n")

# Extract text
print("ğŸ“ Extracting text...")
texts = [doc['text'] for doc in documents]
print(f"âœ… {len(texts)} text chunks ready\n")

# Create embeddings
print("âš¡ Creating embeddings...")
embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)
embeddings = np.array(embeddings, dtype='float32')

print(f"âœ… Shape: {embeddings.shape}\n")

# Build FAISS index
print("ğŸ” Building FAISS index...")
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)
print(f"âœ… Index has {index.ntotal} vectors\n")

# Save
os.makedirs('embeddings', exist_ok=True)
faiss.write_index(index, 'embeddings/layered_advice_faiss.index')

with open('embeddings/layered_advice_metadata.json', 'w', encoding='utf-8') as f:
    json.dump(documents, f, indent=2, ensure_ascii=False)

np.save('embeddings/layered_embeddings.npy', embeddings)

print("="*50)
print("âœ… DONE")
print(f"ğŸ“Š {len(documents)} layer records")
print(f"ğŸ“ {dimension}-dimensional embeddings")
print("="*50)
